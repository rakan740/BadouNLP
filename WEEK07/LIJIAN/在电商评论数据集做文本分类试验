import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
import torch
import time


# 数据加载与预处理
def load_and_preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 数据统计分析
    class_counts = df['sentiment'].value_counts()
    text_lengths = df['text'].str.split().str.len()
    
    print("\n📊 数据统计报告")
    print(f"总样本数: {len(df)}")
    print(f"正样本数: {class_counts[1]} | 负样本数: {class_counts[0]}")
    print(f"文本平均长度: {text_lengths.mean():.2f} tokens")
    print(f"文本长度标准差: {text_lengths.std():.2f}")
    
    return df

# 模型训练与评估基类
class SentimentModel:
    def __init__(self, model_name, tokenizer_name):
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def tokenize(self, texts):
        return self.tokenizer(texts.tolist(), 
                            padding=True,
                            truncation=True,
                            max_length=512,
                            return_tensors='pt')
    
    def train(self, train_dataset, val_dataset):
        training_args = TrainingArguments(
            output_dir='./results',
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=16,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True
        )
        
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
